{
  "os":  "Linux-5.15.0-41-generic-x86_64-with-glibc2.31",
  "python":  "3.10.15",
  "startedAt":  "2024-10-11T13:49:54.908194Z",
  "args":  [
    "--model_name_or_path",
    "meta-llama/Llama-3.1-8B",
    "--data_path",
    "./abortion.json",
    "--bf16",
    "True",
    "--output_dir",
    "/nlp/scr/qinanyu/model_cache/result_alpaca_abortion",
    "--num_train_epochs",
    "3",
    "--per_device_train_batch_size",
    "3",
    "--per_device_eval_batch_size",
    "3",
    "--gradient_accumulation_steps",
    "8",
    "--evaluation_strategy",
    "no",
    "--save_strategy",
    "steps",
    "--save_steps",
    "2000",
    "--save_total_limit",
    "1",
    "--learning_rate",
    "2e-5",
    "--weight_decay",
    "0.",
    "--warmup_ratio",
    "0.03",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "1",
    "--fsdp",
    "full_shard auto_wrap",
    "--fsdp_transformer_layer_cls_to_wrap",
    "LlamaDecoderLayer",
    "--tf32",
    "True"
  ],
  "program":  "/sailhome/qinanyu/sft/stanford_alpaca/train.py",
  "codePath":  "train.py",
  "git":  {
    "remote":  "https://github.com/tatsu-lab/stanford_alpaca.git",
    "commit":  "761dc5bfbdeeffa89b8bff5d038781a4055f796a"
  },
  "email":  "qinan_yu@brown.edu",
  "root":  "/sailhome/qinanyu/sft/stanford_alpaca",
  "host":  "sphinx6",
  "username":  "qinanyu",
  "executable":  "/nlp/scr/qinanyu/miniconda3/envs/alpaca/bin/python",
  "codePathLocal":  "train.py",
  "cpu_count":  128,
  "cpu_count_logical":  255,
  "gpu":  "[NVIDIA A100-SXM4-80GB, NVIDIA A100-SXM4-80GB, NVIDIA A100-SXM4-80GB, NVIDIA A100-SXM4-80GB]",
  "gpu_count":  4,
  "disk":  {
    "/":  {
      "total":  "210106302464",
      "used":  "146886602752"
    }
  },
  "memory":  {
    "total":  "1081995415552"
  },
  "cpu":  {
    "count":  128,
    "countLogical":  255
  },
  "gpu_nvidia":  [
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    }
  ],
  "slurm":  {
    "cluster_name":  "sc2",
    "conf":  "/usr/local/etc/slurm.conf",
    "cpus_on_node":  "2",
    "cpus_per_task":  "2",
    "gpus_on_node":  "4",
    "gtids":  "0",
    "job_account":  "nlp",
    "job_cpus_per_node":  "2",
    "job_gid":  "100",
    "job_gpus":  "2,3,4,5",
    "job_id":  "8750288",
    "job_name":  "test_training",
    "job_nodelist":  "sphinx6",
    "job_num_nodes":  "1",
    "job_partition":  "sphinx",
    "job_qos":  "normal",
    "job_uid":  "24185",
    "job_user":  "qinanyu",
    "jobid":  "8750288",
    "localid":  "0",
    "mem_per_node":  "163840",
    "nnodes":  "1",
    "node_aliases":  "(null)",
    "nodeid":  "0",
    "nodelist":  "sphinx6",
    "open_mode":  "a",
    "prio_process":  "0",
    "procid":  "0",
    "submit_dir":  "/sailhome/qinanyu/sft/stanford_alpaca",
    "submit_host":  "sc.stanford.edu",
    "task_pid":  "1484671",
    "tasks_per_node":  "1",
    "topology_addr":  "sphinx6",
    "topology_addr_pattern":  "node",
    "working_cluster":  "sc2:sc.stanford.edu:6817:9472:109"
  },
  "cudaVersion":  "12.2"
}